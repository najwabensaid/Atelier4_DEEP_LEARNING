{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d329ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train = True, download = True, transform = transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root='./data', train = False, download = True, transform = transforms.ToTensor())\n",
    "xtrain = trainset.data.numpy()\n",
    "ytrain = trainset.targets.numpy()\n",
    "x_val_pre = testset.data[:1000].numpy()\n",
    "y_val = testset.targets[:1000].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef11cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating x_train and y_train with 1000 images from each class and binarizing the pixels\n",
    "count = np.zeros(10)\n",
    "idx = []\n",
    "for i in range(0, len(ytrain)):\n",
    "  for j in range(10):\n",
    "    if(ytrain[i] == j):\n",
    "      count[j] += 1\n",
    "      if(count[j]<=1000):\n",
    "        idx = np.append(idx, i)\n",
    "        \n",
    "y_train = ytrain[idx.astype('int')]\n",
    "x_train_pre = xtrain[idx.astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the images from 28x28 to 14x14\n",
    "r,_,_ = x_train_pre.shape\n",
    "x_train = np.zeros([r,14,14])\n",
    "for i in range(r):\n",
    "  a = cv2.resize(x_train_pre[i].astype('float32'), (14,14)) # Resizing the image from 28*28 to 14*14\n",
    "  x_train[i] = a\n",
    "\n",
    "r,_,_ = x_val_pre.shape\n",
    "x_val = np.zeros([r,14,14])\n",
    "for i in range(r):\n",
    "  a = cv2.resize(x_val_pre[i].astype('float32'), (14,14)) # Resizing the image from 28*28 to 14*14\n",
    "  x_val[i] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fd8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarizing\n",
    "x_train = np.where(x_train > 128, 1, 0)\n",
    "x_val = np.where(x_val > 128, 1, 0)\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_val = x_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataloaders\n",
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader([[x_train[i], y_train[i]] for i in range(len(y_train))], shuffle=True, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader([[x_val[i], y_val[i]] for i in range(len(y_val))], shuffle=True, batch_size=100)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3138ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variational Auto Encoder model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(196, 128) #Encoder\n",
    "        self.fc21 = nn.Linear(128, 8) #mu\n",
    "        self.fc22 = nn.Linear(128, 8) #sigma\n",
    "\n",
    "        self.fc3 = nn.Linear(8, 128) #Decoder\n",
    "        self.fc4 = nn.Linear(128, 196)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = torch.tanh(self.fc1(x))\n",
    "        return self.fc21(h), self.fc22(h) # mu, std\n",
    "    \n",
    "    def sampling(self, mu, std): # Reparameterization trick\n",
    "        eps1 = torch.randn_like(std)\n",
    "        eps2 = torch.randn_like(std)\n",
    "        return 0.5*((eps1 * std + mu) + (eps2 * std + mu)) # Using two samples to compute expectation over z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        h = torch.tanh(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, std = self.encoder(x.view(-1, 196))\n",
    "        z = self.sampling(mu, std)\n",
    "        return self.decoder(z), mu, std\n",
    "model = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "177413e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining loss, optimizer and LR scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.5, \n",
    "                             patience=5, threshold=0.001, cooldown=0,\n",
    "                             min_lr=0.0001, verbose=True)\n",
    "\n",
    "def loss_function(y, x, mu, std): \n",
    "    ERR = F.binary_cross_entropy(y, x.view(-1, 196), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + torch.log(std**2) - mu**2 - std**2)\n",
    "    return ERR + KLD, -ERR, -KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Validating\n",
    "count=0\n",
    "err_l, kld_l, n_wu, testl, update = [], [], [], [], []\n",
    "for epoch in range(1, 20):\n",
    "    \n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(trainloader):\n",
    "        model.train()\n",
    "        data = data.cuda()\n",
    "        bsize = data.shape[0]\n",
    "        recon_batch, mu, std = model(data)\n",
    "        loss, err, kld = loss_function(recon_batch, data, mu, std)\n",
    "        loss.backward()\n",
    "        train_loss += err.item() + kld.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        err_l.append(err.item()/bsize)\n",
    "        kld_l.append(kld.item()/bsize)\n",
    "        count+=1\n",
    "        n_wu.append(count)\n",
    "\n",
    "        if (count%100 == 0): # Validating every 100 weight updates\n",
    "          model.eval()\n",
    "          a, _ = next(iter(testloader))\n",
    "          a = a.cuda()\n",
    "          trecon, tmu, tstd = model(a)\n",
    "          tloss, terr, tkld = loss_function(trecon, a, tmu, tstd)\n",
    "          testl.append(terr/100)\n",
    "          update.append(count)\n",
    "\n",
    "    scheduler.step(train_loss / len(trainloader.dataset))\n",
    "    \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(trainloader.dataset)))\n",
    "    model.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in testloader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, std = model(data)\n",
    "            loss, err, kld = loss_function(recon, data, mu, std)\n",
    "            test_loss += err + kld\n",
    "    \n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd4211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting the first and second term of ELBO as a function of weight updates\n",
    "plt.figure(figsize=(5,3), dpi=100)\n",
    "plt.plot(n_wu, err_l, 'b', label='Reconstruction error')\n",
    "plt.plot(n_wu, kld_l, 'g', label='KL Divergence')\n",
    "plt.title('Plotting first and second term of ELBO')\n",
    "plt.xlabel('Number of weight updates')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing input and output from the VAE from training set\n",
    "model.eval()\n",
    "for i in range(8):\n",
    "  a,t = next(iter(trainloader))\n",
    "  a = a.cuda()\n",
    "  recon, mu, std = model(a[0])\n",
    "  b = recon[0].reshape((14,14))\n",
    "  f, axarr = plt.subplots(1,2)\n",
    "  axarr[0].imshow(a[0].detach().cpu().numpy())\n",
    "  axarr[1].imshow(b.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing input and output of the VAE from validation set\n",
    "model.eval()\n",
    "for i in range(8):\n",
    "  a,t = next(iter(testloader))\n",
    "  a = a.cuda()\n",
    "  recon, mu, std = model(a[0])\n",
    "  b = recon[0].reshape((14,14))\n",
    "  f, axarr = plt.subplots(1,2)\n",
    "  axarr[0].imshow(a[0].detach().cpu().numpy())\n",
    "  axarr[1].imshow(b.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthesizing MNIST images from a Standard Gaussian Distribution\n",
    "for i in range(8):\n",
    "  \n",
    "  x = np.random.normal(0,1, 8)\n",
    "  x= x.astype(np.float32)\n",
    "  x=torch.from_numpy(x)\n",
    "  x= x.cuda()\n",
    "  recon = model.decoder(x)\n",
    "  b = recon.reshape((14,14))\n",
    "  print(x)\n",
    "  f, axarr = plt.subplots(1) \n",
    "  axarr.imshow(b.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5920bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the reconstruction log likelihood term in ELBO on Training vs Validation set\n",
    "plt.figure(figsize=(5,3), dpi=100)\n",
    "plt.plot(err_l, 'g', label='Training Reconstruction log likelihood')\n",
    "plt.plot(update, testl, 'r', label='Validation Reconstruction log likelihood')\n",
    "plt.title('Reconstruction log likelihood of ELBO: Training vs Validation')\n",
    "plt.xlabel('Number of weight updates')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
